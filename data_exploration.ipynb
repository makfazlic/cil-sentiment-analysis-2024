{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.656077Z",
     "start_time": "2024-07-29T15:03:16.650829Z"
    }
   },
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass, field\n",
    "from itertools import islice\n",
    "from typing import Literal, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import wandb\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch import Tensor\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.669072Z",
     "start_time": "2024-07-29T15:03:16.664071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embedding_model, head_model):\n",
    "        super().__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        self.head_model = head_model\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding_model(**x).last_hidden_state[:, 0, :]\n",
    "        output = self.head_model(embedding)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ],
   "id": "60f493968cec5a06",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.680075Z",
     "start_time": "2024-07-29T15:03:16.671072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_step(model, dataloader):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        x, y_true = batch['tokens'], batch['labels']\n",
    "        x = x.to(Config.device)\n",
    "        y_true = y_true.to(Config.device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del batch\n",
    "        del x\n",
    "        del y_true\n",
    "        del y_pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    mean_loss = np.array(losses).mean()\n",
    "    if Config.use_wandb:\n",
    "        wandb.log({\"train loss\": mean_loss})\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def valid_step(model, dataloader, should_be_neg, should_be_pos):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    scores = []\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        x, y_true = batch['tokens'], batch['labels']\n",
    "        x = x.to(Config.device)\n",
    "        y_true = y_true.to(Config.device)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "        y_pred[y_pred >= .5] = 1\n",
    "        y_pred[y_pred < .5] = 0\n",
    "        score = (y_pred == y_true)\n",
    "        scores.append(score)\n",
    "\n",
    "        del batch\n",
    "        del x\n",
    "        del y_true\n",
    "        del y_pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def append_to_scores(df: pd.DataFrame, expected_label: int):\n",
    "        arr = np.array(list([b] for b in df['label'] == expected_label))\n",
    "        if len(arr):\n",
    "            scores.append(arr)\n",
    "            \n",
    "    append_to_scores(should_be_neg, 0)\n",
    "    append_to_scores(should_be_pos, 1)\n",
    "\n",
    "    scores = np.vstack(scores)\n",
    "    accuracy = np.array(scores).mean()\n",
    "    mean_loss = np.array(losses).mean()\n",
    "    if Config.use_wandb:\n",
    "        wandb.log({\"valid loss\": mean_loss})\n",
    "        wandb.log({\"valid accuracy\": accuracy})\n",
    "    return mean_loss, accuracy"
   ],
   "id": "b46da006a40a4ba",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:18:50.689885Z",
     "start_time": "2024-07-29T16:18:50.508638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Name\n",
    "    comment: str = \"cool name for charts\"\n",
    "    \n",
    "    # Stats\n",
    "    use_wandb: bool = False\n",
    "    \n",
    "    # Saving model and info\n",
    "    records_filename: str = \"./work_files/data_exploration/records.csv\"\n",
    "    model_filename_format: str = \"./work_files/data_exploration/models/model{:02}.pkl\"\n",
    "    config_filename_format: str = \"./work_files/data_exploration/configs/config{:02}.pkl\"\n",
    "\n",
    "    # Data\n",
    "    no_of_samples: int = 200000\n",
    "    validation_size: float = 0.05\n",
    "    train_file_neg: str = 'data/train_neg.txt'\n",
    "    train_file_pos: str = 'data/train_pos.txt'\n",
    "    test_file: str = 'data/test_data.txt'\n",
    "    \n",
    "    # Pre-trained model\n",
    "    model_name: str = 'albert-base-v2'\n",
    "    \n",
    "    # Hyperparameters\n",
    "    epochs: int = 5\n",
    "    batch_size: int = 20\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay = float = 1e-4\n",
    "    scheduler_step_size: int = 5\n",
    "    scheduler_gamma: float = 0.5\n",
    "\n",
    "    # LoRA\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: int = 32\n",
    "    lora_target_modules: [str] = field(default_factory=lambda: [\"query\", \"value\"])\n",
    "    lora_dropout: float = 0.5\n",
    "    lora_bias: Literal[\"none\", \"all\", \"lora_only\"] = \"lora_only\"\n",
    "\n",
    "    # Head model\n",
    "    head_model_str: str = field(default_factory=lambda: str(head_model))\n",
    "    last_layer_size = 64\n",
    "    \n",
    "    # Other stuff\n",
    "    device: str = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    random_seed: int = 42\n",
    "\n",
    "\n",
    "embedding_model = AutoModel.from_pretrained(Config.model_name, resume_download=None)\n",
    "head_model = nn.Sequential(nn.Linear(embedding_model.config.hidden_size, Config.last_layer_size),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(Config.last_layer_size, 1))\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=Config.lora_r,\n",
    "    lora_alpha=Config.lora_alpha,\n",
    "    target_modules=Config().lora_target_modules,\n",
    "    lora_dropout=Config.lora_dropout,\n",
    "    bias=Config.lora_bias,\n",
    ")\n",
    "lora_model = get_peft_model(embedding_model, lora_config)\n",
    "my_model = MyModel(lora_model, head_model).to(Config.device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = AdamW(my_model.parameters(), lr=Config.learning_rate, weight_decay=Config.weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=Config.scheduler_step_size, gamma=Config.scheduler_gamma)"
   ],
   "id": "5504cc9c67dd9b7b",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.932447Z",
     "start_time": "2024-07-29T15:03:16.929064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if Config.use_wandb:\n",
    "    wandb.init(\n",
    "        project=\"CIL Project\",\n",
    "        name=Config().comment,\n",
    "        config=Config().__dict__\n",
    "    )\n",
    "    wandb.watch(my_model, log_freq=100)"
   ],
   "id": "bd00e2b7e8a9f456",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.941811Z",
     "start_time": "2024-07-29T15:03:16.933436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_train_data(input_parsing_funs: [Callable[[str], bool]] = None) -> pd.DataFrame:\n",
    "    tweets_set = set()\n",
    "    tweets, labels = [], []\n",
    "\n",
    "    def load_tweets(filename, label):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            count = Config.no_of_samples // 2\n",
    "            for line in tqdm.tqdm(islice(f, count), total=count, desc='Loading Tweets'):\n",
    "                line = line.rstrip()\n",
    "                for fun in input_parsing_funs:\n",
    "                    line = fun(line)\n",
    "                if line not in tweets_set:\n",
    "                    tweets_set.add(line)\n",
    "                    tweets.append(line)\n",
    "                    labels.append(label)\n",
    "\n",
    "    load_tweets(Config.train_file_neg, 0)\n",
    "    load_tweets(Config.train_file_pos, 1)\n",
    "\n",
    "    return pd.DataFrame(data={'tweet': tweets, 'label': labels})\n",
    "\n",
    "\n",
    "class InputParsing:\n",
    "    @staticmethod\n",
    "    def remove_users(words):\n",
    "        return ' '.join([word for word in words.split() if not word == '<user>'])\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_hashtags(words):\n",
    "        return ' '.join([word for word in words.split() if not word.startswith('#')])\n",
    "\n",
    "    @staticmethod\n",
    "    def unify_hashtags(words):\n",
    "        f = lambda word: '<hashtag>' if word.startswith('#') else word\n",
    "        return ' '.join([f(word) for word in words.split()])\n",
    "\n",
    "    @staticmethod\n",
    "    def unify_numbers(words):\n",
    "        f = lambda word: '<number>' if word.isnumeric() else word\n",
    "        return ' '.join([f(word) for word in words.split()])"
   ],
   "id": "75924da821612005",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.946804Z",
     "start_time": "2024-07-29T15:03:16.942803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataframe.iloc[index]"
   ],
   "id": "a71a70e0e17c9eed",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.971767Z",
     "start_time": "2024-07-29T15:03:16.947804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_dataset(dataset):\n",
    "    valid_size = int(Config.validation_size * len(dataset))\n",
    "    train_size = len(dataset) - valid_size\n",
    "    generator = torch.Generator().manual_seed(Config.random_seed)\n",
    "    train_split, valid_split = random_split(dataset, [train_size, valid_size], generator=generator)\n",
    "    return dataset.dataframe.iloc[train_split.indices], dataset.dataframe.iloc[valid_split.indices]\n",
    "\n",
    "\n",
    "def get_dataframes(input_parsing_funs: [Callable[[str], bool]] = None):\n",
    "    return split_dataset(TweetDataset(load_train_data(input_parsing_funs)))"
   ],
   "id": "6c1e3b0691b8da85",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:16.980296Z",
     "start_time": "2024-07-29T15:03:16.973763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_by_filter(\n",
    "        df: pd.DataFrame, \n",
    "        filter_fun: Callable[[str], bool]) -> (pd.DataFrame, pd.DataFrame):\n",
    "    filtered = df['tweet'].apply(filter_fun)\n",
    "    return df[filtered == True], df[filtered == False]\n",
    "\n",
    "\n",
    "def split_into_neg_unknown_pos(\n",
    "        df: pd.DataFrame, \n",
    "        neg_filter: Callable[[str], bool],\n",
    "        pos_filter: Callable[[str], bool]) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    pos, rest = split_by_filter(df, pos_filter)\n",
    "    neg, unknown = split_by_filter(rest, neg_filter)\n",
    "    return neg, unknown, pos\n",
    "\n",
    "\n",
    "class TweetFilters:\n",
    "    @staticmethod\n",
    "    def unclosed_parenthesis(tweet):\n",
    "        return tweet.count('(') > tweet.count(')')\n",
    "\n",
    "    @staticmethod\n",
    "    # EXAMPLE FILTER FUNCTION\n",
    "    def has_word_frame(tweet):\n",
    "        return 'frame' in tweet\n",
    "\n",
    "    @staticmethod\n",
    "    # EXAMPLE FILTER FUNCTION\n",
    "    def has_word_thanks(tweet):\n",
    "        return 'thanks' in tweet\n",
    "    \n",
    "    @staticmethod\n",
    "    def no_filter(tweet):\n",
    "        return False"
   ],
   "id": "417ac8a183363815",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:18.432599Z",
     "start_time": "2024-07-29T15:03:16.981289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_parsing_funs = [\n",
    "    InputParsing.unify_hashtags,\n",
    "]\n",
    "neg_filter = TweetFilters.has_word_frame\n",
    "pos_filter = TweetFilters.has_word_thanks\n",
    "\n",
    "train_df, valid_df = get_dataframes(input_parsing_funs)\n",
    "_, train_df, _ = split_into_neg_unknown_pos(train_df, neg_filter, pos_filter)\n",
    "neg_valid, valid_df, pos_valid = split_into_neg_unknown_pos(valid_df, neg_filter, pos_filter)\n",
    "\n",
    "train_dataset = TweetDataset(train_df)\n",
    "valid_dataset = TweetDataset(valid_df)"
   ],
   "id": "91fec64fa0288abf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Tweets: 100%|██████████| 100000/100000 [00:00<00:00, 154393.53it/s]\n",
      "Loading Tweets: 100%|██████████| 100000/100000 [00:00<00:00, 175535.31it/s]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:03:18.439885Z",
     "start_time": "2024-07-29T15:03:18.434596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gen_tokenize_fun():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Config.model_name, resume_download=None)\n",
    "\n",
    "    def tokenize(data):\n",
    "        tweets = [x[\"tweet\"] for x in data]\n",
    "        labels = Tensor([[x[\"label\"]] for x in data])\n",
    "        output = tokenizer(tweets, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "        return {\"tokens\": output, \"labels\": labels}\n",
    "\n",
    "    return tokenize\n",
    "\n",
    "\n",
    "def make_dataloader(dataset, shuffle: bool):\n",
    "    return DataLoader(dataset=dataset,\n",
    "                      collate_fn=gen_tokenize_fun(),\n",
    "                      batch_size=Config.batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      pin_memory=True)\n",
    "\n",
    "\n",
    "def get_dataloaders(train_dataset, valid_dataset):\n",
    "    return (make_dataloader(train_dataset, shuffle=True),\n",
    "            make_dataloader(valid_dataset, shuffle=False))"
   ],
   "id": "530b0194d231c9eb",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:15:48.041050Z",
     "start_time": "2024-07-29T15:03:18.440881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader, valid_loader = get_dataloaders(train_dataset, valid_dataset)\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{Config.epochs}:\")\n",
    "\n",
    "    train_loss = train_step(my_model, train_loader)\n",
    "    valid_loss, valid_accuracy = valid_step(my_model, valid_loader, neg_valid, pos_valid)\n",
    "\n",
    "    print(f\"  TRAIN loss     = {train_loss}\")\n",
    "    print(f\"  VALID loss     = {valid_loss}\")\n",
    "    print(f\"  VALID accuracy = {valid_accuracy}\")\n",
    "    print(f\"--------------------------------------------------------\")\n",
    "\n",
    "    scheduler.step()"
   ],
   "id": "d48e124c3eda5303",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8310/8310 [13:35<00:00, 10.19it/s]\n",
      "100%|██████████| 438/438 [00:18<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN loss     = 0.4153375732455802\n",
      "  VALID loss     = 0.38497350065539415\n",
      "  VALID accuracy = 0.8289749531060355\n",
      "--------------------------------------------------------\n",
      "Epoch 2/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8310/8310 [13:38<00:00, 10.15it/s]\n",
      "100%|██████████| 438/438 [00:18<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN loss     = 0.3578870075238167\n",
      "  VALID loss     = 0.34439962332617474\n",
      "  VALID accuracy = 0.8445327154363897\n",
      "--------------------------------------------------------\n",
      "Epoch 3/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8310/8310 [14:15<00:00,  9.71it/s]\n",
      "100%|██████████| 438/438 [00:20<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN loss     = 0.33691375745789887\n",
      "  VALID loss     = 0.3334837592032538\n",
      "  VALID accuracy = 0.8508220236124904\n",
      "--------------------------------------------------------\n",
      "Epoch 4/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8310/8310 [14:44<00:00,  9.40it/s]\n",
      "100%|██████████| 438/438 [00:19<00:00, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN loss     = 0.3243768064652611\n",
      "  VALID loss     = 0.3314586176396641\n",
      "  VALID accuracy = 0.8534701533708485\n",
      "--------------------------------------------------------\n",
      "Epoch 5/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8310/8310 [14:37<00:00,  9.47it/s]\n",
      "100%|██████████| 438/438 [00:19<00:00, 22.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN loss     = 0.3156106497070312\n",
      "  VALID loss     = 0.32689556781389667\n",
      "  VALID accuracy = 0.854683879510096\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:15:48.136578Z",
     "start_time": "2024-07-29T16:15:48.076057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model(model, accuracy: float, description: str = ''):\n",
    "    records = pd.read_csv(Config.records_filename, index_col='Index')\n",
    "    index = len(records)\n",
    "    model_filename = Config.model_filename_format.format(index)\n",
    "    config_filename = Config.config_filename_format.format(index)\n",
    "\n",
    "    records.loc[model_filename] = {'Accuracy': accuracy, 'Description': description}\n",
    "    pickle.dump(model, open(model_filename, 'wb'))\n",
    "    pickle.dump(Config(), open(config_filename, 'wb'))\n",
    "    records.to_csv(Config.records_filename)\n",
    "\n",
    "\n",
    "def load_model(index):\n",
    "    model_filename = Config.model_filename_format.format(index)\n",
    "    return pickle.load(open(model_filename, 'rb'))\n",
    "\n",
    "\n",
    "def load_config(index):\n",
    "    config_filename = Config.config_filename_format.format(index)\n",
    "    return pickle.load(open(config_filename, 'rb'))\n",
    "\n",
    "\n",
    "def load_records():\n",
    "    return pd.read_csv(Config.records_filename, index_col='Index')"
   ],
   "id": "4cabf95118c0c297",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:19:44.924691Z",
     "start_time": "2024-07-29T16:19:44.848259Z"
    }
   },
   "cell_type": "code",
   "source": "save_model(my_model, valid_accuracy, Config.comment)",
   "id": "11e2f71074b0004c",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:19:46.219439Z",
     "start_time": "2024-07-29T16:19:46.151347Z"
    }
   },
   "cell_type": "code",
   "source": "load_records()",
   "id": "4a38a8f32762b91c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  Accuracy  \\\n",
       "Index                                                        \n",
       "models/model00.sav                                0.866050   \n",
       "models/model01.pkl                                0.841000   \n",
       "models/model02.pkl                                0.798870   \n",
       "models/model03.pkl                                0.854866   \n",
       "models/model04.pkl                                0.854866   \n",
       "models/model05.pkl                                0.850457   \n",
       "models/model06.pkl                                0.850457   \n",
       "models/model07.pkl                                0.849565   \n",
       "models/model08.pkl                                0.859129   \n",
       "models/model09.pkl                                0.859901   \n",
       "models/model10.pkl                                0.866740   \n",
       "models/model11.pkl                                0.858577   \n",
       "models/model12.pkl                                0.863812   \n",
       "models/model13.pkl                                0.834494   \n",
       "models/model14.pkl                                0.858199   \n",
       "models/model15.pkl                                0.837030   \n",
       "models/model16.pkl                                0.865938   \n",
       "models/model17.pkl                                0.866049   \n",
       "models/model18.pkl                                0.861304   \n",
       "models/model19.pkl                                0.870793   \n",
       "models/model20.pkl                                0.862077   \n",
       "models/model21.pkl                                0.864534   \n",
       "models/model22.pkl                                0.864173   \n",
       "models/model23.pkl                                0.873331   \n",
       "models/model24.pkl                                0.874021   \n",
       "models/model25.pkl                                0.870733   \n",
       "models/model26.pkl                                0.876227   \n",
       "models/model27.pkl                                0.875979   \n",
       "models/model28.pkl                                0.881964   \n",
       "models/model29.pkl                                0.886266   \n",
       "models/model30.pkl                                0.847987   \n",
       "models/model31.pkl                                0.879731   \n",
       "models/model32.pkl                                0.876972   \n",
       "./work_files/data_exploration/models/model33.pkl  0.854684   \n",
       "./work_files/data_exploration/models/model34.pkl  0.854684   \n",
       "\n",
       "                                                                                        Description  \n",
       "Index                                                                                                \n",
       "models/model00.sav                                                                       base model  \n",
       "models/model01.pkl                                                                 small test model  \n",
       "models/model02.pkl                                                       small test - no duplicates  \n",
       "models/model03.pkl                                                           model 100k no hashtags  \n",
       "models/model04.pkl                                                           model 100k no hashtags  \n",
       "models/model05.pkl                                                          model 100k yes hashtags  \n",
       "models/model06.pkl                                                          model 100k yes hashtags  \n",
       "models/model07.pkl                                     model 100k - unclosed parenthesis always neg  \n",
       "models/model08.pkl                                     model 200k - unclosed parenthesis always neg  \n",
       "models/model09.pkl                                                                       model 200k  \n",
       "models/model10.pkl                                                     model 200k high LoRA dropout  \n",
       "models/model11.pkl                                                   200k high dropout, parenthesis  \n",
       "models/model12.pkl                                                   200k high dropout, no hashtags  \n",
       "models/model13.pkl                                200k high dropout, unified hashtags, unified n...  \n",
       "models/model14.pkl                                                  200k high dropout removed users  \n",
       "models/model15.pkl                                               unify users, frame neg, thanks pos  \n",
       "models/model16.pkl                                               unify users, frame neg, thanks pos  \n",
       "models/model17.pkl                                                           unify users, frame neg  \n",
       "models/model18.pkl                                                unify #tags, unclosed parenthesis  \n",
       "models/model19.pkl                                                       50% dropout, unified #tags  \n",
       "models/model20.pkl                                                       60% dropout, unified #tags  \n",
       "models/model21.pkl                                                                  bert-base-cased  \n",
       "models/model22.pkl                                                   bert-base-cased, unified #tags  \n",
       "models/model23.pkl                                                           roberta, unified #tags  \n",
       "models/model24.pkl                                                                          roberta  \n",
       "models/model25.pkl                                                       roberta, unify big numbers  \n",
       "models/model26.pkl                                                               roberta, LoRA bias  \n",
       "models/model27.pkl                                                roberta, LoRA bias, unified #tags  \n",
       "models/model28.pkl                                                                        gte-large  \n",
       "models/model29.pkl                                                   multilingual-e5-large-instruct  \n",
       "models/model30.pkl                                                                 all-MiniLM-L6-v2  \n",
       "models/model31.pkl                                              gte-large, LoRA bias, unified #tags  \n",
       "models/model32.pkl                                gte-large, LoRA bias, unified #tags, more dropout  \n",
       "./work_files/data_exploration/models/model33.pkl                               cool name for charts  \n",
       "./work_files/data_exploration/models/model34.pkl                               cool name for charts  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>models/model00.sav</th>\n",
       "      <td>0.866050</td>\n",
       "      <td>base model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model01.pkl</th>\n",
       "      <td>0.841000</td>\n",
       "      <td>small test model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model02.pkl</th>\n",
       "      <td>0.798870</td>\n",
       "      <td>small test - no duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model03.pkl</th>\n",
       "      <td>0.854866</td>\n",
       "      <td>model 100k no hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model04.pkl</th>\n",
       "      <td>0.854866</td>\n",
       "      <td>model 100k no hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model05.pkl</th>\n",
       "      <td>0.850457</td>\n",
       "      <td>model 100k yes hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model06.pkl</th>\n",
       "      <td>0.850457</td>\n",
       "      <td>model 100k yes hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model07.pkl</th>\n",
       "      <td>0.849565</td>\n",
       "      <td>model 100k - unclosed parenthesis always neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model08.pkl</th>\n",
       "      <td>0.859129</td>\n",
       "      <td>model 200k - unclosed parenthesis always neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model09.pkl</th>\n",
       "      <td>0.859901</td>\n",
       "      <td>model 200k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model10.pkl</th>\n",
       "      <td>0.866740</td>\n",
       "      <td>model 200k high LoRA dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model11.pkl</th>\n",
       "      <td>0.858577</td>\n",
       "      <td>200k high dropout, parenthesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model12.pkl</th>\n",
       "      <td>0.863812</td>\n",
       "      <td>200k high dropout, no hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model13.pkl</th>\n",
       "      <td>0.834494</td>\n",
       "      <td>200k high dropout, unified hashtags, unified n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model14.pkl</th>\n",
       "      <td>0.858199</td>\n",
       "      <td>200k high dropout removed users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model15.pkl</th>\n",
       "      <td>0.837030</td>\n",
       "      <td>unify users, frame neg, thanks pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model16.pkl</th>\n",
       "      <td>0.865938</td>\n",
       "      <td>unify users, frame neg, thanks pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model17.pkl</th>\n",
       "      <td>0.866049</td>\n",
       "      <td>unify users, frame neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model18.pkl</th>\n",
       "      <td>0.861304</td>\n",
       "      <td>unify #tags, unclosed parenthesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model19.pkl</th>\n",
       "      <td>0.870793</td>\n",
       "      <td>50% dropout, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model20.pkl</th>\n",
       "      <td>0.862077</td>\n",
       "      <td>60% dropout, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model21.pkl</th>\n",
       "      <td>0.864534</td>\n",
       "      <td>bert-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model22.pkl</th>\n",
       "      <td>0.864173</td>\n",
       "      <td>bert-base-cased, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model23.pkl</th>\n",
       "      <td>0.873331</td>\n",
       "      <td>roberta, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model24.pkl</th>\n",
       "      <td>0.874021</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model25.pkl</th>\n",
       "      <td>0.870733</td>\n",
       "      <td>roberta, unify big numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model26.pkl</th>\n",
       "      <td>0.876227</td>\n",
       "      <td>roberta, LoRA bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model27.pkl</th>\n",
       "      <td>0.875979</td>\n",
       "      <td>roberta, LoRA bias, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model28.pkl</th>\n",
       "      <td>0.881964</td>\n",
       "      <td>gte-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model29.pkl</th>\n",
       "      <td>0.886266</td>\n",
       "      <td>multilingual-e5-large-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model30.pkl</th>\n",
       "      <td>0.847987</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model31.pkl</th>\n",
       "      <td>0.879731</td>\n",
       "      <td>gte-large, LoRA bias, unified #tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models/model32.pkl</th>\n",
       "      <td>0.876972</td>\n",
       "      <td>gte-large, LoRA bias, unified #tags, more dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./work_files/data_exploration/models/model33.pkl</th>\n",
       "      <td>0.854684</td>\n",
       "      <td>cool name for charts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./work_files/data_exploration/models/model34.pkl</th>\n",
       "      <td>0.854684</td>\n",
       "      <td>cool name for charts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:19:47.289509Z",
     "start_time": "2024-07-29T16:19:47.285508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if Config.use_wandb:\n",
    "    wandb.finish()"
   ],
   "id": "ba76838e75aa02ca",
   "outputs": [],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
